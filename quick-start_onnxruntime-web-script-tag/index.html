<!DOCTYPE html>
<html>
    <header>
        <title>ONNX Runtime JavaScript examples: Quick Start - Web (using script tag)</title>
    </header>
    <body>
        <!-- import ONNXRuntime Web from CDN -->
        <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
        <script>
            // use an async context to call onnxruntime functions.
            async function main() {
                try {
                    // create a new session and load the specific model.
                    //
                    // the model in this example contains a single MatMul node
                    // it has 2 inputs: 'a'(float32, 3x4) and 'b'(float32, 4x3)
                    // it has 1 output: 'c'(float32, 3x3)
                    const session = await ort.InferenceSession.create('../model/tf_model.onnx');

                    // prepare inputs. a tensor need its corresponding TypedArray as data
                    const dataTest = Float32Array.from([6.7, 3.1, 4.4, 1.4]);
                    const tensorTest = new ort.Tensor('float32', dataTest, [1, 4]);

                    // prepare feeds. use model input names as keys.
                    const feeds = {'tensor_input':tensorTest}

                    // feed inputs and run
                    const results = await session.run(feeds);

                    // read from results
                    const output = results.tensor_output.data;
                    document.write(`data of result tensor output: ${output}`);

                } catch (e) {
                    document.write(`failed to inference ONNX model: ${e}.`);
                }
            }
            main();
        </script>
    </body>
</html>